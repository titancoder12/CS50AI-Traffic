My experimentation process in this project was somewhat random. However, while I experimented with different combinations of layers, I found something quite intruiguing. At first, I thought that the more layers and units, the better. However, I found that the belief I had was not quite true. When I took away my sophisticated model with many layers and units, it seemed to run faster (most likely due to the fact that there were less units to train) and suprisingly, have better accuracy! With the metrics for loss, I attempted to minimize loss by increasing the dropout, but not to the extent that it would decrease accuracy.  